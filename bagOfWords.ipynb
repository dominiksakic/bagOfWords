{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominiksakic/bagOfWords/blob/main/bagOfWords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS1mTvP9KxoF",
        "outputId": "fd85b648-942b-40b8-eda5-531c476fef97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  24.7M      0  0:00:03  0:00:03 --:--:-- 24.7M\n"
          ]
        }
      ],
      "source": [
        "# Download and unzip data\n",
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup\n",
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLo9Xez6_tsZ",
        "outputId": "2f1c4a1e-2f36-4121-fe12-75e5d892c728"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'aclImdb/train/unsup': No such file or directory\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5AJ-elzQlc8"
      },
      "source": [
        "- Goal is to produce a ensambled model where each model is is optimized by the keras tuner.\n",
        "  - Transformer, Sequence to Seq, and Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Mwn0PtLhLlpq"
      },
      "outputs": [],
      "source": [
        "import os, pathlib, shutil, random\n",
        "\n",
        "# Create a Validation set\n",
        "base_dir = pathlib.Path('aclImdb')\n",
        "val_dir = base_dir / 'val' # No need for string concat, thanks to pathlib\n",
        "train_dir = base_dir / 'train'\n",
        "for category in (\"neg\", \"pos\"):\n",
        "  os.makedirs(val_dir / category, exist_ok=True)\n",
        "  files = os.listdir(train_dir / category)\n",
        "  random.Random(1337).shuffle(files)\n",
        "  num_val_samples = int(0.2 *len(files))\n",
        "  val_files = files[-num_val_samples:]\n",
        "  for fname in val_files:\n",
        "    shutil.move(train_dir / category /fname, val_dir / category / fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w_iRuMuPY84",
        "outputId": "0693869c-d7ef-432d-82ed-c0a396640507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16000 files belonging to 2 classes.\n",
            "Found 9000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=batch_size)\n",
        "\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/val', batch_size=batch_size)\n",
        "\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test', batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "cpKm9ZX9_6iK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_model(hp):\n",
        "  max_tokens = 20000\n",
        "\n",
        "  # Tune the numer of units in the first layer\n",
        "  hidden_dim = hp.Int(\"hidden_dim\", min_value=16, max_value=128, step=16)\n",
        "\n",
        "  # Tune the dropout\n",
        "  dropout_rate = hp.Float(\"float\", min_value=0.1, max_value=0.6, step=0.1)\n",
        "\n",
        "  # Tune the optimizer\n",
        "  optimizer = hp.Choice(\"optimizer\", values=[\"adam\", \"rmsprop\", \"sgd\"])\n",
        "\n",
        "  inputs = keras.Input(shape=(max_tokens,))\n",
        "  x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "  x = layers.Dropout(dropout_rate)(x)\n",
        "  outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  model = keras.Model(inputs, outputs)\n",
        "  model.compile(optimizer=optimizer,\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "PbcreUyKAQKx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"binary_2gram_bayes\"\n",
        ")\n",
        "\n",
        "tuner.search(binary_2gram_train_ds.cache(),\n",
        "             validation_data=binary_2gram_val_ds.cache(),\n",
        "             epochs=10,\n",
        "             callbacks=[\n",
        "                 keras.callbacks.EarlyStopping(patience=3)\n",
        "             ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV-61RGDAZhs",
        "outputId": "176e231a-6976-4eb1-9f1d-7eebcef72558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 00m 34s]\n",
            "val_accuracy: 0.8980000019073486\n",
            "\n",
            "Best val_accuracy So Far: 0.8980000019073486\n",
            "Total elapsed time: 00h 01m 28s\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "48                |16                |hidden_dim\n",
            "0.5               |0.1               |float\n",
            "sgd               |rmsprop           |optimizer\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.6297 - loss: 0.6456 - val_accuracy: 0.8301 - val_loss: 0.4740\n",
            "Epoch 2/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8136 - loss: 0.4600 - val_accuracy: 0.8499 - val_loss: 0.3823\n",
            "Epoch 3/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.8466 - loss: 0.3799 - val_accuracy: 0.8598 - val_loss: 0.3425\n",
            "Epoch 4/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8693 - loss: 0.3279 - val_accuracy: 0.8681 - val_loss: 0.3208\n",
            "Epoch 5/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8880 - loss: 0.2918 - val_accuracy: 0.8751 - val_loss: 0.3035\n",
            "Epoch 6/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9020 - loss: 0.2656 - val_accuracy: 0.8800 - val_loss: 0.2919\n",
            "Epoch 7/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9127 - loss: 0.2423 - val_accuracy: 0.8816 - val_loss: 0.2840\n",
            "Epoch 8/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9186 - loss: 0.2289 - val_accuracy: 0.8842 - val_loss: 0.2784\n",
            "Epoch 9/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9274 - loss: 0.2053 - val_accuracy: 0.8853 - val_loss: 0.2764\n",
            "Epoch 10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\", save_best_only=True)\n",
        "]\n",
        "\n",
        "best_model.fit(binary_2gram_train_ds.cache(),\n",
        "               validation_data=binary_2gram_val_ds.cache(),\n",
        "               epochs=10,\n",
        "               callbacks=callbacks)\n",
        "\n",
        "# Load and evaluate\n",
        "model = keras.models.load_model(\"binary_2gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")\n"
      ],
      "metadata": {
        "id": "2Hoi0a0YCCc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters\n",
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "\n",
        "print(\"\\nBest hyperparameters:\")\n",
        "for param in best_hp.values:\n",
        "    print(f\"{param}: {best_hp.get(param)}\")\n"
      ],
      "metadata": {
        "id": "OHGv48Q7FC98"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcB1DUJwTxxg9ly+6RhMXB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}